{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61353,"status":"ok","timestamp":1745826533836,"user":{"displayName":"Titouan LESTANGUET","userId":"09164533689640689148"},"user_tz":-120},"id":"UMfbZEJVl59F","outputId":"745b1d99-e819-43f4-9481-cd22f10a5f45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision.transforms as transforms\n","from torchvision import datasets, models, transforms\n","from torch.utils.data import DataLoader, Dataset, random_split, WeightedRandomSampler\n","from torchvision.datasets import ImageFolder\n","from tqdm import tqdm\n","import numpy as np\n","import os\n","from google.colab import drive\n","from collections import Counter\n","drive.mount('/content/drive')\n","import sys\n","sys.path.append('/content/drive/MyDrive/TR_DIMA/Logit_compensation/')\n","from logitadjust import LogitAdjust\n","\n","\n","# Path to the dataset and model\n","path_train_dataset = \"/content/drive/MyDrive/TR_DIMA/training_set_reduit\"\n","\n","# Transformations for the dataset\n","base_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Resize images to 224x224\n","    transforms.ToTensor(),  # Convert images to PyTorch tensors\n","])\n","\n","augmented_transform = transforms.Compose([\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.GaussianBlur(kernel_size=9, sigma=(0.01, 5)),\n","        transforms.RandomResizedCrop(size=224, scale=(0.7, 1.0), ratio = (0.2,5)),\n","        transforms.ToTensor(),\n","    ])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmbGLyLkmyMv"},"outputs":[],"source":["# Load the training dataset\n","\n","dataset_init = datasets.ImageFolder(root=path_train_dataset, transform=augmented_transform)\n","\n","train_size = int(0.8 * len(dataset_init))\n","valid_size = len(dataset_init) - train_size\n","\n","train_dataset, valid_dataset = random_split(dataset_init, [train_size, valid_size])\n","\n","# Create DataLoaders for training and validation datasets\n","\n","train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=10, pin_memory=True)\n","val_loader = DataLoader(valid_dataset, batch_size=128, shuffle=False, num_workers=10, pin_memory=True)\n","\n","valid_classes = dataset_init.classes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jvMhWu7IxHfe"},"outputs":[],"source":["num_all = Counter(dataset_init.targets)\n","distrib = [num_all[i] for i in range(0,13)]"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":475,"status":"ok","timestamp":1745847280534,"user":{"displayName":"Titouan LESTANGUET","userId":"09164533689640689148"},"user_tz":-120},"id":"GgEKRQKKm6y9"},"outputs":[],"source":["model = models.resnet50(pretrained=True)\n","model.fc = nn.Linear(model.fc.in_features, len(valid_classes))\n","\n","# Device config\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the model to the device\n","model.to(device)\n","\n","# Define the loss function and optimizer\n","criterion = LogitAdjust(distrib,tau=1.9,weight=None)\n","optimizer = optim.Adam(model.parameters(), lr=1e-5)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hDL9ZxFdw-kl","outputId":"aee3be8b-ac3c-4edb-d8a1-e6287163677e","executionInfo":{"status":"ok","timestamp":1745848441446,"user_tz":-120,"elapsed":1155862,"user":{"displayName":"Titouan LESTANGUET","userId":"09164533689640689148"}}},"outputs":[{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss = 0.5203, Val Loss = 0.2648\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 2: Train Loss = 0.2188, Val Loss = 0.1812\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 3: Train Loss = 0.1660, Val Loss = 0.1502\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 4: Train Loss = 0.1446, Val Loss = 0.1361\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 5: Train Loss = 0.1276, Val Loss = 0.1329\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 6: Train Loss = 0.1147, Val Loss = 0.1226\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 7: Train Loss = 0.1066, Val Loss = 0.1092\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 8: Train Loss = 0.0991, Val Loss = 0.1005\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 9: Train Loss = 0.0914, Val Loss = 0.1053\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 10: Train Loss = 0.0863, Val Loss = 0.1078\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 11: Train Loss = 0.0803, Val Loss = 0.1035\n"]},{"output_type":"stream","name":"stderr","text":[]},{"output_type":"stream","name":"stdout","text":["Epoch 12: Train Loss = 0.0767, Val Loss = 0.1049\n"]},{"output_type":"stream","name":"stderr","text":["                                                                                "]},{"output_type":"stream","name":"stdout","text":["Epoch 13: Train Loss = 0.0719, Val Loss = 0.1035\n","Early stopping déclenché.\n"]},{"output_type":"stream","name":"stderr","text":["\r"]}],"source":["# Training function\n","\n","num_epochs = 100\n","patience = 5\n","early_stopping_counter = 0\n","best_val_loss = float('inf')\n","gradients = []\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    running_loss = 0.0\n","    train_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", leave=False)\n","\n","    for inputs, labels in train_bar:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        train_bar.set_postfix(loss=loss.item())\n","\n","    train_loss = running_loss / len(train_loader.dataset)\n","\n","    # Validation\n","    model.eval()\n","    val_loss = 0.0\n","    val_bar = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val]\", leave=False)\n","\n","    with torch.no_grad():\n","        for inputs, labels in val_bar:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            val_loss += loss.item() * inputs.size(0)\n","            val_bar.set_postfix(loss=loss.item())\n","\n","    val_loss = val_loss / len(val_loader.dataset)\n","\n","    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n","\n","    # Early stopping\n","    if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        patience_counter = 0\n","        torch.save(model.state_dict(), \"/content/drive/MyDrive/TR_DIMA/Entrainement/best_model_logit_adjustment_1_9.pth\")\n","    else:\n","        patience_counter += 1\n","        if patience_counter >= patience:\n","            print(\"Early stopping déclenché.\")\n","            break\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNQBlCa60QTTXU+lrII0pCa"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}